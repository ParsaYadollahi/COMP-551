{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 5. CNN using Keras\n",
        "- Using TensforFlow we create a CNN with 2 convolutional and 2 fully connected layers"
      ],
      "metadata": {
        "id": "NCSEMhkFfS8b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aq5a3wC-82dH",
        "outputId": "bf3a627b-b636-4658-b8aa-39f2c7b48946"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy version: 1.21.5\n",
            "pandas version: 1.3.5\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings                  \n",
        "import tensorflow as tf\n",
        "from keras.layers.convolutional import Convolution2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dense\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "import time\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"numpy version:\", np.__version__)\n",
        "print(\"pandas version:\", pd.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Acquire Data"
      ],
      "metadata": {
        "id": "5wZa7U33fyRq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiAzSkLU_4c_",
        "outputId": "69338364-1106-49b2-d231-87fac1766589"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of x_train data: (60000, 784)\n",
            "shape of x_test data: (10000, 784)\n",
            "shape of y_train data: (60000,)\n",
            "shape of y_test data: (10000,)\n"
          ]
        }
      ],
      "source": [
        "#load the data, vectorize it\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "unormalized_x_train = x_train\n",
        "unormalized_x_test = x_test\n",
        "\n",
        "# normalization to [0,1] range\n",
        "x_train = x_train / 255\n",
        "x_test = x_test /255\n",
        "\n",
        "## reshape the inputs\n",
        "x_train = x_train.reshape(x_train.shape[0], -1)\n",
        "print(\"shape of x_train data: \" + str(x_train.shape))\n",
        "\n",
        "x_test = x_test.reshape(x_test.shape[0], -1)\n",
        "print(\"shape of x_test data: \" + str(x_test.shape))\n",
        "\n",
        "print(\"shape of y_train data: \" + str(y_train.shape))\n",
        "print(\"shape of y_test data: \" + str(y_test.shape))\n",
        "\n",
        "#reshaping unormalized images\n",
        "raw_data_train = unormalized_x_train.reshape(unormalized_x_train.shape[0], -1)\n",
        "raw_data_test = unormalized_x_test.reshape(unormalized_x_test.shape[0], -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "U3idXiJdB0ej"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ilumK7jgEv-g"
      },
      "outputs": [],
      "source": [
        "x_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdZeVKxoE9g5",
        "outputId": "199553fd-5bf5-4140-ac7b-7f17de656bd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (48000, 28, 28, 1)\n",
            "x_validate shape: (12000, 28, 28, 1)\n",
            "x_test shape: (10000, 28, 28, 1)\n",
            "y_train shape: (48000, 10)\n",
            "y_validate shape: (12000,)\n",
            "y_test shape: (10000, 10)\n"
          ]
        }
      ],
      "source": [
        "rows, cols = 28, 28\n",
        "input_shape = (rows, cols, 1)\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], rows, cols, 1)\n",
        "x_validate = x_validate.reshape(x_validate.shape[0], rows, cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], rows, cols, 1)\n",
        "\n",
        "# One hot tencoding\n",
        "y_train = np_utils.to_categorical(y_train, 10)\n",
        "y_test = np_utils.to_categorical(y_test, 10)\n",
        "\n",
        "# normalizing\n",
        "x_train = x_train / 255\n",
        "x_validate = x_validate / 255\n",
        "x_test = x_test / 255\n",
        "\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(\"x_validate shape:\", x_validate.shape)\n",
        "print(\"x_test shape:\", x_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_validate shape:\", y_validate.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "PjXAy_aUFHyD"
      },
      "outputs": [],
      "source": [
        "import keras # main keras package\n",
        "from keras.models import Sequential # sequential model\n",
        "from keras.layers import Dropout, Flatten, AveragePooling2D # layers with layers operations\n",
        "from keras.layers import Dense,Conv2D  # layers types\n",
        "from tensorflow.keras.layers import BatchNormalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0v9upym6FTbN",
        "outputId": "c08ce1f4-9494-4979-95fc-82bbc79a9617"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "375/375 [==============================] - 55s 145ms/step - loss: 0.9900 - accuracy: 0.6604\n",
            "Epoch 2/10\n",
            "375/375 [==============================] - 54s 145ms/step - loss: 0.5716 - accuracy: 0.7939\n",
            "Epoch 3/10\n",
            "375/375 [==============================] - 53s 143ms/step - loss: 0.4974 - accuracy: 0.8234\n",
            "Epoch 4/10\n",
            "375/375 [==============================] - 53s 142ms/step - loss: 0.4595 - accuracy: 0.8376\n",
            "Epoch 5/10\n",
            "375/375 [==============================] - 52s 138ms/step - loss: 0.4321 - accuracy: 0.8478\n",
            "Epoch 6/10\n",
            "375/375 [==============================] - 51s 137ms/step - loss: 0.4151 - accuracy: 0.8537\n",
            "Epoch 7/10\n",
            "375/375 [==============================] - 53s 141ms/step - loss: 0.3982 - accuracy: 0.8590\n",
            "Epoch 8/10\n",
            "375/375 [==============================] - 51s 137ms/step - loss: 0.3866 - accuracy: 0.8648\n",
            "Epoch 9/10\n",
            "375/375 [==============================] - 51s 135ms/step - loss: 0.3755 - accuracy: 0.8685\n",
            "Epoch 10/10\n",
            "375/375 [==============================] - 53s 142ms/step - loss: 0.3667 - accuracy: 0.8708\n",
            "\n",
            "The time taken to train the model is:  562.5472767353058\n",
            "#### MODEL SUMMARY ####\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_11 (Conv2D)          (128, 28, 28, 10)         100       \n",
            "                                                                 \n",
            " activation_16 (Activation)  (128, 28, 28, 10)         0         \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (128, 27, 27, 10)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (128, 27, 27, 10)         910       \n",
            "                                                                 \n",
            " activation_17 (Activation)  (128, 27, 27, 10)         0         \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (128, 26, 26, 10)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (128, 6760)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (128, 128)                865408    \n",
            "                                                                 \n",
            " dense_11 (Dense)            (128, 10)                 1290      \n",
            "                                                                 \n",
            " activation_18 (Activation)  (128, 10)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 867,708\n",
            "Trainable params: 867,708\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "def create_CNN_model(kernel_size = (3, 3), dropout_rate = 0, filters = 10, activation_ftn = \"relu\", epochs = 10, num_convolutions = 2):\n",
        "  start = time.time()\n",
        "  model = Sequential()\n",
        "\n",
        "  # adding conv layer \n",
        "  for conv in range(num_convolutions):\n",
        "    model.add(Convolution2D(filters = filters,\n",
        "                            kernel_size = kernel_size,\n",
        "                            padding = \"same\"\n",
        "                            ))\n",
        "    model.add(Activation(activation = activation_ftn))\n",
        "    model.add(MaxPooling2D(pool_size = (2, 2), strides = (1, 1)))\n",
        "\n",
        "  # Flatten the network\n",
        "  model.add(Flatten())\n",
        "\n",
        "  # Fully-connected hidden && output layer\n",
        "  model.add(Dense(128))\n",
        "  model.add(Dense(10))\n",
        "\n",
        "  # Add a softmax activation function\n",
        "  model.add(Activation(\"softmax\"))\n",
        "\n",
        "  model.compile(loss = \"categorical_crossentropy\",\n",
        "                optimizer = SGD(lr = 0.01),\n",
        "                metrics = [\"accuracy\"]\n",
        "              )\n",
        "\n",
        "  # Train\n",
        "  model.fit(x_train, y_train, batch_size = 128, epochs = epochs, verbose = 1)\n",
        "  end = time.time()\n",
        "  print(\"\\nThe time taken to train the model is: \", end-start)\n",
        "\n",
        "  return model\n",
        "\n",
        "model = create_CNN_model()\n",
        "\n",
        "print(\"#### MODEL SUMMARY ####\")\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "xizw6cXwQA4-"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# losses = [1.0983,\n",
        "#           0.6579,\n",
        "#           0.5707,\n",
        "#           0.5146,\n",
        "#           0.4761,\n",
        "#           0.4477,\n",
        "#           0.4253,\n",
        "#           0.4112,\n",
        "#           0.3958,\n",
        "#           0.3831,\n",
        "#           0.3739,\n",
        "#           0.3635,\n",
        "#           0.3559,\n",
        "#           0.3493,\n",
        "#           0.3424,\n",
        "#           0.3371,\n",
        "#           0.3317,\n",
        "#           0.3255,\n",
        "#           0.3204,\n",
        "#           0.3170]\n",
        "\n",
        "# epochs = [i for i in range(20)]\n",
        "\n",
        "# plt.plot(epochs, losses, color='green') \n",
        "# plt.ylabel('loss') \n",
        "# plt.xlabel('epochs')\n",
        "\n",
        "# plt.title('Losses over epochs')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "9A17XaJtPha7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5f3ed47-474a-43da-b38a-0a04b1ac61ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 4s 42ms/step - loss: 0.3839 - accuracy: 0.8646\n",
            "The accuracy for the CNN model is: 0.8646000027656555\n"
          ]
        }
      ],
      "source": [
        "(_, accuracy) = model.evaluate(x_test, y_test, batch_size = 128, verbose = 1)\n",
        "print(\"The accuracy for the CNN model is:\", accuracy)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CNN_LetNet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}